# Chest_X-ray_object_detection_project
Kaggle - VinBigData chest X-ray abnormalities detection contest </br>
url: https://www.kaggle.com/competitions/vinbigdata-chest-xray-abnormalities-detection/overview </br>

### ğŸ«Introduction
* Why Chest X-ray?
  * Chest X-rayëŠ” ê¸°ë³¸ì¤‘ì— ê¸°ë³¸ì¸ ê²€ì‚¬.
  * ìƒëª…ê³¼ ì§ê²°ë˜ëŠ” ë¶€ìœ„ì´ê¸° ë•Œë¬¸ì— ì •í™•í•œ ì§„ë‹¨ì´ í•„ìš”í•˜ë‹¤.
  * ë‹¤ë¥¸ ë¶€ìœ„ì˜ X-rayì™€ëŠ” ë‹¤ë¥´ê²Œ ë†“ì¹  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ë¶€ìœ„ë¼ ë§ê³  ë§ì€ X-ray dataì¤‘ chest X-rayë¥¼ ì„ íƒí•˜ì˜€ë‹¤.
  
* Why Chest X-ray needs AI?
  * ì˜ˆë¥¼ ë“¤ì–´ ì¢…ì–‘ íŒë…ì˜ ê²½ìš° ì¢…ì–‘ì´ í¬ë‹¤ë©´ ëˆ„êµ¬ë‚˜ íŒë…ì´ ê°€ëŠ¥í•˜ë‹¤. í•˜ì§€ë§Œ ë§Œì•½ ê²°ì ˆì˜ sizeê°€ ì‘ë‹¤ë©´ ë†“ì¹  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ ìˆë‹¤.
  * ì´ë ‡ê²Œ ë³‘ë³€ì„ ë†“ì¹˜ì§€ ì•Šê¸°ìœ„í•´ AIê°€ ì˜ì‚¬ì˜ ë„ì›€ì´ ë˜ì–´ ì§„ë‹¨ì— ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤.
  * ë˜í•œ ì¼ë°˜ X-ray ì „ë¬¸ì˜ì‚¬(ë°©ì‚¬ì„ ê³¼)ê°€ ì•„ë‹ˆë”ë¼ë„ íŒë…ì— ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆê¸°ë•Œë¬¸ì— AIë¥¼ ì´ìš©í•œë‹¤ë©´ ì¢€ ë” ì •í™•í•˜ê²Œ íŒë…ì´ ê°€ëŠ¥í•  ê²ƒì´ë‹¤.
* purpose </br>
íì™€ ê´€ë ¨ëœ 14ê°€ì§€ì˜ ì§ˆë³‘ì„ detectingí•˜ì—¬ data augmentationì— ë”°ë¥¸ ì—¬ëŸ¬ modelì˜ performance ë¹„êµ

### ğŸ«Materials & Methods
* Materials
  * Vietnam hospitals dataset </br>
  (the Hospital 108 and the Hanoi Medical University Hospital)
  * train images: 15,000 (normal: 10,606, patient: 4,394)
  * test images: 3,000
  * bbox info: image_id, class_id, x_min, y_min, x_max, y_max
  * ë³‘ëª… ì‚¬ì „ì¡°ì‚¬: </br>
  https://www.notion.so/63d70daf163d4c82b4027d85a9bc9e86

* Methods
  * Tools: OpenCV, PyTorch, numpy, pandas, sklearn, seaborn, matplotlib
  * Augmentations: Rotation(90Âº), Flip(horizontal), Zoomin(10%), Cutmix, CLAHE, Equlization, Mosaic
  * Models: EfficientDet(ì†Œì •), Faster R-CNN(ë´‰í•™,í˜„ë‚˜), YOLOX(ìˆ˜í˜„)
  * Workflow
   <img src="https://user-images.githubusercontent.com/61971952/193194200-5f44aa1e-2fd4-410a-be1b-1d16b6be21cc.png" width=70% height=70%>

### ğŸ«Results
* EDA
  * ì •ìƒì¸ì˜ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ì ì€ ì–‘ì˜ í™˜ì ë°ì´í„°ë§Œ ë‚¨ìŒ
  * ë¼ë²¨ ê°„ì˜ ê·¹ë‹¨ì ì¸ ì–‘ ì°¨ì´ -> ë°ì´í„° ë¶ˆê· í˜•
  * ë‹¨ì¼ ì´ë¯¸ì§€ì•ˆì— ë‹¤ì¤‘ ë¼ë²¨
  * <img src="https://user-images.githubusercontent.com/61971952/193209874-ebc78a59-5b58-4816-8412-c841a3b6099f.png" width="600" height="400"/>

* Augmentationì— ë”°ë¥¸ dataset ì¢…ë¥˜
  * category A: no augmentation (4,394ì¥)
  * category B: rotation, flip, zoomin (17,576ì¥)
  * categroy C: rotation, flip, zoomin, cutmix, CLAHE, equalization, mosaic (30,758ì¥)
  * category D: ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œë¥¼ ìœ„í•´ ê°€ì¥ ì ì€ ì–‘ì˜ ë¼ë²¨ì„ ê°–ëŠ” ì‚¬ì§„ë§Œ augmentationì„ ì ìš©í•˜ê³  ë‚˜ë¨¸ì§€ ë¼ë²¨ì€ down sampling (5,999ì¥)
  * <img src="https://user-images.githubusercontent.com/61971952/193212025-c29832b9-b649-41f9-8e58-7ad8a5b25c56.png" width="400" height="200"/>
  </br>

  Category A | Category B | Category C | Category D
  ------|-------|-------|-------|
   ì›ë³¸ | ROTATION | ROTATION | ROTATION 
   &nbsp; | FLIP | FLIP | FLIP 
   &nbsp; | ZOOM IN | ZOOM IN | ZOOM IN 
   &nbsp; |  | CUTMIX | CUTMIX
   &nbsp; |  | CLAHE | CLAHE
   &nbsp; |  | EQUALIZATION | EQUALIZATION
   &nbsp; |  | MOSAIC | MOSAIC
  </br>
  
* Modelì— ë”°ë¥¸ ì„±ëŠ¥ ë¹„êµ(kaggle score)
</br>

Model | Category A | Category B | Category C | Category D
-------|-------|-------|-------|-------|
EfficientDet | 0.038 | 0.046 | 0.052 | --
Faster R-CNN | 0.012 | 0.098 | 0.013 | --
YOLOX  |  0.021  | 0.068 | 0.147 | 0.070
   
</br>


### ğŸ«Discussion
* Bioì˜ trendì¸ object detection ì„ ê³µë¶€í•˜ê¸° ìœ„í•˜ì—¬ ì„ íƒí•œ í”„ë¡œì íŠ¸
* í•™ìŠµ dataì•ˆì—ì„œ train & validë¡œ ë‚˜ëˆ„ì§€ ì•Šê³  group k-foldë¥¼ ì‚¬ìš©í–ˆë˜ ì´ìœ ?
  * ì ì€ data setì— ëŒ€í•˜ì—¬ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆë‹¤.
  * âˆµ training/validation/test ì„¸ê°œì˜ ì§‘ë‹¨ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ê²ƒë³´ë‹¤ training & testë¡œë§Œ ë¶„ë¥˜ì‹œ í•™ìŠµí•  dataê°€ ë” ë§ê²Œë˜ì–´ underfittingë“± ì„±ëŠ¥ì´ ë¯¸ë‹¬ë˜ëŠ” modelë¡œ í•™ìŠµë˜ì§€ ì•Šë„ë¡ í•¨.
  * ë˜í•œ 1ê°œì˜ ì´ë¯¸ì§€ì— ë‹¤ì¤‘ labelì´ë¯€ë¡œ ì˜ˆì¸¡ì˜ ì •í™•ë„ë¥¼ í™•ì‹¤íˆ í‰ê°€í•˜ê¸°ìœ„í•´ train set & validì— í¬í•¨ëœ imageê°€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ í•˜ê¸°ìœ„í•˜ì—¬ k-foldì¤‘ì—ì„œë„ group k-foldë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.
  * í•˜ì§€ë§Œ í•™ìŠµ ì‹œê°„ì´ ê½¤ ì˜¤ë˜ê±¸ë ¤ ì‹œê°„ìƒ k = 1 ë¡œ ì„¸íŒ…í•´ ë†“ì•˜ìŒ. </br>
(ì¦‰, kfoldë¥¼ í•˜ì§€ ì•Šê³  train:valid = 8:2ë¡œ ë°ì´í„°ì…‹ì„ ë‚˜ëˆ  í•™ìŠµí•œ ê²ƒê³¼ ê°™ìŒ.)
  * 10epochìœ¼ë¡œ í•™ìŠµì‹œ k=1ë¡œë§Œ ë³¸ê²ƒê³¼ k=5ë¡œ í•˜ì—¬ ì„±ëŠ¥ì„ ë¹„êµí•œ ê²°ê³¼ public scoreê°€ 0.014ì—ì„œ 0.025ë¡œ í–¥ìƒë¨ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. 
  * ê·¸ëŸ¬ë¯€ë¡œ ë°ì´í„°ë¥¼ augmenationí•œ Bì™€ Cë„ ì œëŒ€ë¡œ k = 5ë¡œ ì„¸íŒ…í•´ì„œ í•™ìŠµí–ˆë‹¤ë©´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ì„ ë“¯ í•˜ë‹¤.

   </br>

   k | EPOCH | Score | EPOCH | Score
   -------|-------|-------|-------|-------|
   1 | 10e | 0.014 | 20e | 0.016
   5 | 10e | 0.025 | 20e | 0.024

   </br>

* Zoom in augmentationì‹œ 10%ë¡œ í•œ ì´ìœ ? </br>
  * 10%ë³´ë‹¤ ë” zoom inì„ í–ˆì„ê²½ìš° ì´ë¯¸ì§€ì˜ ê°€ì¥ìë¦¬ì— ìœ„ì¹˜í•˜ë˜ ë³‘ë³€ë“¤ì´ ì˜ë¦¬ëŠ” ê²½ìš°ë“¤ì´ ìˆì–´ì„œ ì´ë¥¼ ë§‰ê¸°ìœ„í•´ 10%ì •ë„ë§Œ zoom inì„ í•˜ì˜€ë‹¤.
* normalization í›„ ë‹¤ì‹œ size(512x512) ì¬ì •ì˜ì‹œ ì •ìˆ˜í™”í•¨ì—ë”°ë¼ ê°™ì€ ê°’ì„ ê°–ê²Œë˜ëŠ” ê²½ìš°ê°€ ìˆì—ˆë‹¤.
  * ë³‘ë³€ì´ ë„ˆë¬´ë„ ì‘ì•„ bboxì˜ y_maxì™€ y_minì´ ë³„ ì°¨ì´ê°€ ë‚˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸. </br>
ì´ëŸ° ë°ì´í„°ë¡œì¸í•´ í•™ìŠµì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ í•´ë‹¹ ë°ì´í„°(10ê°œ ë¯¸ë§Œ)ëŠ” ì‚­ì œí•˜ê¸°ë¡œ í•¨.
* Model selection
  * 1 stage model
    * YOLOX: 1 stageì—ì„œ ìœ ëª…í•˜ê³  ì†ë„ê°€ ë¹ ë¥´ê¸°ë•Œë¬¸ì— ì‚¬ìš©í•¨.
    * EfficientDet (one-stage detector paradigm ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±ë¨): ì‚¬ëŒë“¤ì´ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” YOLO v5ë³´ë‹¤ average precisionì´ ì¢‹ê¸°ë•Œë¬¸ì— ì„ íƒ.
  * 2 stage model
    * Faster R-CNN: ì´ì „ ìˆ˜ì—…ì—ì„œ ì‚¬ìš©í–ˆë˜ modelì´ 1 stageë¼ì„œ 2 stage ê³µë¶€ ê²¸ ì—¬ì „íˆ í˜„ì—­ìœ¼ë¡œ ì“°ì´ê³  ìˆëŠ” ê¸°ì´ˆì ì¸ ëª¨ë¸ì´ë¼ì„œ ì„ íƒí•˜ì˜€ìŒ.
* í•™ìŠµí•˜ëŠ” data ì–‘ì´ 15,000ì¥ì¸ì¤„ ì•Œì•˜ì§€ë§Œ dataë¥¼ ë¶„ì„í•œ ê²°ê³¼ ì •ìƒì¸ì„ ì œì™¸í•œ í™˜ìì˜ dataëŠ” 4,394ì¥ì´ì—ˆë‹¤. </br>
  * ì§ˆë³‘ì„ í•™ìŠµí•´ì•¼í•˜ëŠ” modelì´ê¸°ë•Œë¬¸ì— í™˜ìì˜ dataë§Œ ê°–ê³  í•™ìŠµì„ ì‹œì¼œì•¼í•˜ëŠ”ë° dataì˜ ì–‘ì´ ë„ˆë¬´ ì ì–´ ì–‘ì„ ëŠ˜ë¦¬ê¸° ìœ„í•˜ì—¬ ì—¬ëŸ¬ augmentationì„ ì ìš©í•´ë³´ì•˜ë‹¤.
  * Augmentationì— ë”°ë¥¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ë¹„êµí•´ ë³´ê¸°ìœ„í•´ augmentationì„ ì•ˆí•œ Aê·¸ë£¹ê³¼ ê¸°ë³¸ì ì¸ augmentationì„ í•œ Bê·¸ë£¹, ë§ˆì§€ë§‰ìœ¼ë¡œ ê¸°ë³¸ì ì¸ augmentationì™¸ ì—¬ëŸ¬ ë‹¤ì–‘í•œ ê¸°ë²•ê¹Œì§€ ì ìš©í•œ Cê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ì—ˆë‹¤.
  * ê·¸ ê²°ê³¼ 3ê°œì˜ model ëª¨ë‘ augmentationì„ í•˜ë©´ í• ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒë¨ì„ í™•ì¸í•˜ì˜€ë‹¤.
* Dataë‚´ì—ì„œ ëª¨ë“  labelì´ ë¹„ìŠ·í•œ ì–‘ìœ¼ë¡œ ì¡´ì¬í•˜ì§€ì•Šê³  íŠ¹ì • labelìœ„ì£¼ë¡œ ì¡´ì¬í•˜ê³ ìˆë‹¤. ì¦‰, data imbalanceê°€ ì‹¬í•œìƒí™©. </br>
  * Data imbalance ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë„ˆë¬´ ë§ì€ ì–‘ì„ ê°–ê³ ìˆëŠ” íŠ¹ì • label(0,3,11,13)ì€ down samplingí•˜ê³  ì ì€ ì–‘ì„ ê°–ëŠ” label(1,12)ì—” ì—¬ëŸ¬ê°€ì§€ augmentationìœ¼ë¡œ up samplingí•˜ëŠ” ì‘ì—…ì„ í•˜ì˜€ë‹¤.
  * 1,12ì—ëŠ” Rotation, Flip, Zoomin, Cutmix, CLAHE, Equalization ì„ ì ìš©í•˜ê³  </br>
0,3,11,13ì€ ì•½ 3,000ê°œë¡œ down samplingí•˜ì—¬ labelê°„ì˜ ê·¹ë‹¨ì ì¸ ì°¨ì´ê°€ ì–´ëŠì •ë„ í•´ì†Œëœ Dê·¸ë£¹ì„ ë§Œë“¤ì—ˆë‹¤. </br>
  * ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ê³  í•™ìŠµì†ë„ê°€ ë¹ ë¥¸ YOLOXë¡œ Dê·¸ë£¹ì„ í•™ìŠµí•œ ê²°ê³¼ **Aê·¸ë£¹ì— ë¹„í•´ ì„±ëŠ¥ì´ í–¥ìƒë¨** ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆê³  **ì–‘ì´ ì ì€ë°ë„ ë¶ˆêµ¬í•˜ê³  ê¸°ë³¸ 3ê°€ì§€ augmentationì„ í•œ Bê·¸ë£¹ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤.** </br>
  * í•˜ì§€ë§Œ ê¸°ë³¸ augmentationì™¸ì— ì¶”ê°€ì ì¸ augmentationì„ í–ˆë˜ Cê·¸ë£¹ë³´ë‹¤ëŠ” ì„±ëŠ¥ì´ ëœ ë‚˜ì™”ë‹¤. </br>
(ì´ëŠ” dataì˜ ì–‘ì´ 6ë°°ë‚˜ ì°¨ì´ê°€ ë‚˜ê¸°ë•Œë¬¸ì— ë‚˜ì˜¨ ê²°ê³¼)
  * Cê·¸ë£¹ì—ì„œ í›¨ì”¬ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ê²ƒì„ í†µí•´ data imbalanceë¥¼ í•´ê²°í•œê²ƒë³´ë‹¤ëŠ” dataì˜ ì–‘ì´ ì¶©ë¶„íˆ ìˆëŠ”ê²ƒì´ ì„±ëŠ¥í–¥ìƒì— ë” ë§ì€ íš¨ê³¼ê°€ ìˆìŒì„ ìœ ì¶”í•  ìˆ˜ ìˆì—ˆê³  </br>
**imbalanceì™€ dataì˜ ì–‘ì„ ë™ì‹œì— í•´ê²°í•œë‹¤ë©´ ì´ë³´ë‹¤ í›¨ì”¬ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ ì‹¶ë‹¤.**

### Ref
- https://www.kaggle.com/code/dschettler8845/visual-in-depth-eda-vinbigdata-competition-data
- https://www.kaggle.com/code/yerramvarun/pytorch-fasterrcnn-with-group-kfold-14-class
- https://www.kaggle.com/code/pestipeti/vinbigdata-fasterrcnn-pytorch-inference/notebook
- https://www.kaggle.com/code/pestipeti/vinbigdata-fasterrcnn-pytorch-train/notebook

### MEMO
##### Faster R-CNN
Faster R-CNN use the 'Pascal VOC dataset format'.
In 'Pascal VOC format', the bbox is represented as [x_min, y_min, x_max, y_max']

##### YOLO
In 'YOLO', the bbox is represented as [x_mid, y_mid, width, height]
